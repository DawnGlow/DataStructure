// 로그함수와 같은 그래프를 그리는 (x축 데이터, y축 시간) 형태 vs 지수함수와 같은 그래프를 그리는 형태
/*
시간 복잡도 : 얼마나 빠른가?
공간 복잡도 : 얼마나 메모리를 적게 쓰는가? (메모리의 접근에 따른 속도 자체가 증가하기 때문)
일반적으론 시간 복잡도를 더 중요시 한다.
# 시간복잡도의 평가 방법
- 중심이 되는 특정 연산의 횟수를 세어서 평가
- 데이터의 수에 대한 연산횟수의 함수 T(n)을 구한다.
# 알고리즘의 수행 속도 비교 기준
- 데이터의 수가 적은 경우의 수행 속도는 큰 의미가 없다.
- 데이터의 수에 따른 수행 속도의 변화 정도를 기준으로 한다.
- 어떤 유형을 보이며 속도가 증가하는지가 중요!
*/

// 순차 탐색 알고리즘
int LSearch(int ar[], int len, int target) {
    int i;
    for (i = 0; i < len; i++) {  // <, ++ 연산자
        if (ar[i] == target) {   // == 연산자 : 이 코드에서 중심이 되는 연산자.
            return i;
        }
    }
    return -1;
}
/*
# 중심이 되는 연산자
- 주변이 되는 연산자의 연산 횟수는 중심이 되는 연산자의 연산 횟수에 의존적이다.
ex) == 가 true를 반환할 때 까지 <와 ++이 연산을 함
*/

/*
## 최악의 경우와 최상의 경우 // T(n) = 1
# 순차 탐색 상황 하나 : 운이 좋은 경우
- 배열의 맨 앞에서 대상을 찾는 경우
- 만족스러운 상황이므로 성능평가의 주 관심이 아님!
- '최상의 경우' 라고 함.

# 순차 탐색 상황 둘 : 운이 좋지 않은 경우 // T(n) = n
- 배열의 끝에서 찾거나 대상이 저장되지 않은 경우
- 만족스럽지 못한 상황이므로 성능평가의 주 관심이다!
- '최악의 경우'라 함.

## 평균적인 경우
# 가장 현실적인 경우에 해당한다.
- 일반적으로 등장하는 상황에 대한 경우의 수이다.
- 최상의 경우와 달리 알고리즘 평가에 도움이 된다.
- 하지만 계산하기가 어렵다. 객관적 평가가 쉽지 않다.

# 평균적인 경우의 계산이 어려운 이유
- 평균적인 경우의 연출이 어렵다.
- 평균적인 경우임을 증명하기 어렵다.
- 평균적인 경우는 상황에 따라 달라짐

## 순차탐색 최악의 경우 시간복잡도
- 데이터의 수가 n개 일 때 연산횟수는 n이므로 T(n) = n

## 순차탐색 평균적 경우 시간복잡도
- 가정 1. 탐색 대상이 배열에 존재하지 않을 확률 50%
- 가정 2. 배열 첫 요소부터 마지막 요소까지 탐색대상 존재 확률 동일!

- 탐색 대상이 존재하지 않는 경우의 연산횟수는 n (50%)
- 가정 2에 의해서 탐색 대상이 존재하는 경우의 연산횟수는 n/2 (50%)
-> 1/2 * n + n/2 * 1/2 = 3/4 * n
*/

/*
## 이진 탐색 알고리즘_1 (가운데 인덱싱-> 또 가운데 인덱싱 -> ...)

* 순차 탐색보다 훨씬 좋은 성능을 보이지만, 배열이 정렬되어 있어야 한다는 제약이 따른다.
예시) 3을 배열에서 찾는다고 하자. {1, 2, 3, 7, 9, 12, 21, 23, 27}

첫 번째 시도
- 1. 배열 인덱스의 시작과 끝은 각각 0과 8이다.
- 2. 0과 8을 합하여 그 결과를 2로 나눔
- 3. 2로 나눠서 얻은 결과 4를 인덱스 값으로 하여 arr[4]에 저장된 값이 3인지 확인.

두 번째 시도
- 1. arr[4]에 저장된 값 9와 탐색 대상인 3의 대소를 비교.
- 2. 대소 비교결과가 arr[4] > 3 이므로 탐색 범위를 0~3으로 제한
- 3. 0과 3을 더하여 그 결과를 2로 나누고 나머지는 버림.
- 4. 2로 나눠서 얻은 결과가 1이니 arr[1] == 3인지 확인

세 번째 시도
- 1. arr[1]에 저장된 값 2와 탐색 대상인 3의 대소를 비교
- 2. arr[1] < 3 이므로 탐색 범위 인덱스 기준 2~ 3으로 제한
- 3. 2와 3을 더해서 2로 나눈 나머지 버림
- 4. 결과가 2이니 arr[2] == 3인지 확인

--> 이진 탐색의 매 과정마다 탐색의 대상을 반씩 줄여 나가서 순차 탐색보다 좋은 성능을 보임

## 대상이 배열에 없다면??
- 탐색 범위 first와 last가 만났다는 것은 탐색 대상이 하나 남았다는 것을 뜻함!
- 따라서 first와 last가 역전될 때 까지 탐색의 과정을 계속 반복
while (first <= last) {
  // 이진 탐색 알고리즘의 진행
}
*/

int BSearch(int ar[], int len, int target) {
    int first = 0;
    int last = len - 1;
    int mid;

    while (first <= last) {
        mid = (first + last) / 2;
        if (target == ar[mid]) {
            return mid;
        } else {
            if (target < ar[mid]) {
                last = mid - 1;
            } else {
                first = mid + 1;
            }
        }
    }
    return -1;
}

// -1 혹은 +1을 추가하지 않으면 first <= mid <= last가 항상 성립되서, 탐색 대상이 존재하지 않는 경우 first와 last의 역전 현상이 발생하지 않는다.

/*
## 이진 탐색 알고리즘 최악의 경우 시간복잡도1
1. 핵심 연산을 찾자.
- target == ar[mid]에 따라 while문, mid = (f + l) / 2의 실행여부가 결정됨
- target == ar[mid]가 중심이 되는 연산

n개일때 == 연산 -> n/2개일때 == 연산 -> n/4개일때 == 연산 ->..... -> 1개일 때 == 연산
--> 몇번 == 연산 했는지가 중요

8 -> 4 -> 2 -> 1 : 2로 나누기 3번하면서 비교연산 3회 진행, 1개 남았을 때 비교 연산 1회 --> 4회
; n이 1이 되기까지 2로 나눈 횟수 k회. 마지막 비교연산 1회 --> T(n) = k + 1

그럼 K는 무엇인가요?
n일 때 k번 (1/2)를 곱해서 1이 된다 --> n * (1/2)^k = 1, 2^k = n
--> k = log2(n)

T(n) = log2(n) + 1

하지만 시간복잡도의 목적은 n에 따른 T(n)의 증감의 정도를 판단하는 것이므로 +1은 생략한다.
따라서 T(n) = log2(n)
Q) +200이여도 생략이 가능한가요?
ans) 시간 복잡도를 판단하는데 관점이 어디에 있냐에 따라 판단(ex. 데이터가 많은 경우, 데이터가 적은 경우)
ans2) + 10000000 같은 것은 값이 1개여도 엄청 오래걸림 --> 판단의 가치가 없음.

이러한 것들을 정리한 것이 빅오 표기법

## 빅-오 표기법 (큰 O로 감싸서 표현함.)
T(n)에서 실제로 영향력을 끼치는 부분을 가리켜 빅-오 라고 한다.
ex) T(n) = n^2 + 2*n + 1
1차 근사치 식) n^2 + 2*n
2차 근사치 식) n^2
T(n)의 빅-오 : O(n^2)

* 빅오 결정의 일반화
T(n) = a_m * n^m + a_m-1 * n^m-1 .... -> O(n^m) : 중요한 것은 패턴이기 때문!

2^n > n^3> n^2 > nlogn > n > logn > 1

## 빅-오 에 대한 수학적 접근
수학적 정의) f(n), g(n)에 대하여 모든 n>=k 에 대하여 f(n) <= C * g(n)을 만족한는 두개의 상수 C와 K가 존재하면,
f(n)의 빅-오는 O(g(n)) 이다.



*/